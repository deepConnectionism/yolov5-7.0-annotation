# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Loss functions
"""

import torch
import torch.nn as nn

from utils.metrics import bbox_iou
from utils.torch_utils import de_parallel


def smooth_BCE(eps=0.1):  # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441
    """ç”¨åœ¨ComputeLossç±»ä¸­
    æ ‡ç­¾å¹³æ»‘æ“ä½œ  [1, 0]  =>  [0.95, 0.05]
    :params eps: å¹³æ»‘å‚æ•°
    :return positive, negative label smoothing BCE targets  ä¸¤ä¸ªå€¼åˆ†åˆ«ä»£è¡¨æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„æ ‡ç­¾å–å€¼
            åŸå…ˆçš„æ­£æ ·æœ¬=1 è´Ÿæ ·æœ¬=0 æ”¹ä¸º æ­£æ ·æœ¬=1.0 - 0.5 * eps  è´Ÿæ ·æœ¬=0.5 * eps
    """
    # return positive, negative label smoothing BCE targets
    return 1.0 - 0.5 * eps, 0.5 * eps


class BCEBlurWithLogitsLoss(nn.Module):
    """ BCEå‡½æ•°çš„ä¸€ä¸ªæ›¿ä»£ï¼Œæ˜¯yolov5ä½œè€…çš„ä¸€ä¸ªå®éªŒæ€§çš„å‡½æ•°
    ç”¨åœ¨ComputeLossç±»çš„__init__å‡½æ•°ä¸­
    https://github.com/ultralytics/yolov5/issues/1030
    The idea was to reduce the effects of false negatives (missing labels), which can occur often in COCO and other datasets.
    ä½¿ç”¨èµ·æ¥ç›´æ¥åœ¨ComputeLossç±»çš„__init__å‡½æ•°ä¸­æ›¿ä»£ä¼ ç»Ÿçš„BCEå‡½æ•°å³å¯
    """
    # BCEwithLogitLoss() with reduced missing label effects.
    def __init__(self, alpha=0.05):
        super().__init__()
        self.loss_fcn = nn.BCEWithLogitsLoss(reduction='none')  # must be nn.BCEWithLogitsLoss()
        self.alpha = alpha

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)
        pred = torch.sigmoid(pred)  # prob from logits
        # dx = [-1, 1]  å½“pred=1 true=0æ—¶(ç½‘ç»œé¢„æµ‹è¯´è¿™é‡Œæœ‰ä¸ªobjä½†æ˜¯gtè¯´è¿™é‡Œæ²¡æœ‰), dx=1 => alpha_factor=0 => loss=0
        # è¿™ç§å°±æ˜¯æ£€æµ‹æˆæ­£æ ·æœ¬äº†ä½†æ˜¯æ£€æµ‹é”™äº†ï¼ˆfalse positiveï¼‰æˆ–è€…missing labelçš„æƒ…å†µ è¿™ç§æƒ…å†µä¸åº”è¯¥è¿‡å¤šçš„æƒ©ç½š->loss=0
        dx = pred - true  # reduce only missing label effects
        # å¦‚æœé‡‡æ ·ç»å¯¹å€¼çš„è¯ ä¼šå‡è½»predå’Œgtå·®å¼‚è¿‡å¤§è€Œé€ æˆçš„å½±å“
        # dx = (pred - true).abs()  # reduce missing label and false label effects
        alpha_factor = 1 - torch.exp((dx - 1) / (self.alpha + 1e-4))
        loss *= alpha_factor
        return loss.mean()


class FocalLoss(nn.Module):
    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    """FocalLossæŸå¤±å‡½æ•°æ¥è‡ª Kaiming Heåœ¨2017å¹´å‘è¡¨çš„ä¸€ç¯‡è®ºæ–‡ï¼šFocal Loss for Dense Object Detection. 
    è¿™ç¯‡è®ºæ–‡è®¾è®¡çš„ä¸»è¦æ€è·¯: å¸Œæœ›é‚£äº›hard exampleså¯¹æŸå¤±çš„è´¡çŒ®å˜å¤§ï¼Œä½¿ç½‘ç»œæ›´å€¾å‘äºä»è¿™äº›æ ·æœ¬ä¸Šå­¦ä¹ ã€‚é˜²æ­¢ç”±äºeasy examplesè¿‡å¤šï¼Œä¸»å¯¼æ•´ä¸ªæŸå¤±å‡½æ•°ã€‚
    ä¼˜ç‚¹ï¼š
        è§£å†³äº† one-stage object detection ä¸­å›¾ç‰‡ä¸­æ­£è´Ÿæ ·æœ¬ï¼ˆå‰æ™¯å’ŒèƒŒæ™¯ï¼‰ä¸å‡è¡¡çš„é—®é¢˜ï¼› é™ä½ç®€å•æ ·æœ¬çš„æƒé‡ï¼Œä½¿æŸå¤±å‡½æ•°æ›´å…³æ³¨å›°éš¾æ ·æœ¬ï¼›

    ç”¨åœ¨ä»£æ›¿åŸæœ¬çš„BCEclsï¼ˆåˆ†ç±»æŸå¤±ï¼‰å’ŒBCEobjï¼ˆç½®ä¿¡åº¦æŸå¤±ï¼‰
    è®ºæ–‡: https://arxiv.org/abs/1708.02002
    https://blog.csdn.net/qq_38253797/article/details/116292496
    TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py
    """
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super().__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss() å®šä¹‰ä¸ºå¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°
        self.gamma = gamma # å‚æ•°gamma  ç”¨äºå‰Šå¼±ç®€å•æ ·æœ¬å¯¹lossçš„è´¡çŒ®ç¨‹åº¦
        self.alpha = alpha # å‚æ•°alpha  ç”¨äºå¹³è¡¡æ­£è´Ÿæ ·æœ¬ä¸ªæ•°ä¸å‡è¡¡çš„é—®é¢˜
        self.reduction = loss_fcn.reduction # self.reduction: æ§åˆ¶FocalLossæŸå¤±è¾“å‡ºæ¨¡å¼ sum/mean/none  é»˜è®¤æ˜¯Mean
        # focallossä¸­çš„BCEå‡½æ•°çš„reduction='None'  BCEä¸ä½¿ç”¨Sumæˆ–è€…Mean 
        # éœ€è¦å°†Focal lossåº”ç”¨äºæ¯ä¸€ä¸ªæ ·æœ¬ä¹‹ä¸­
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        # æ­£å¸¸BCEçš„loss:   loss = -log(p_t)
        loss = self.loss_fcn(pred, true)
        # p_t = torch.exp(-loss)
        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability

        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py
        pred_prob = torch.sigmoid(pred)  # prob from logits
        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = (1.0 - p_t) ** self.gamma # è¿™é‡Œä»£è¡¨Focal lossä¸­çš„æŒ‡æ•°é¡¹
        loss *= alpha_factor * modulating_factor # è¿”å›æœ€ç»ˆçš„loss=BCE * ä¸¤ä¸ªå‚æ•°  (çœ‹çœ‹å…¬å¼å°±è¡Œäº† å’Œå…¬å¼ä¸€æ¨¡ä¸€æ ·)
        # æœ€åé€‰æ‹©focallossè¿”å›çš„ç±»å‹ é»˜è®¤æ˜¯mean
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss


class QFocalLoss(nn.Module):
    # Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    """QFocalLossæŸå¤±å‡½æ•°æ¥è‡ª20å¹´çš„ä¸€ç¯‡æ–‡ç« ï¼š 
             Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection.
    åšå®¢ï¼šhttps://zhuanlan.zhihu.com/p/147691786
    ç”¨æ¥ä»£æ›¿FocalLoss
    QFocalLoss æ¥è‡ªGeneral Focal Lossè®ºæ–‡: https://arxiv.org/abs/2006.04388
    Args:
        nn (_type_): _description_
    """
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super().__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)

        pred_prob = torch.sigmoid(pred)  # prob from logits
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = torch.abs(true - pred_prob) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss


class ComputeLoss:
    sort_obj_iou = False # åé¢ç­›é€‰ç½®ä¿¡åº¦æŸå¤±æ­£æ ·æœ¬çš„æ—¶å€™æ˜¯å¦å…ˆå¯¹iouæ’åº

    # Compute losses
    def __init__(self, model, autobalance=False):
        # è·å–æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡
        device = next(model.parameters()).device  # get model device
        # è·å–æ¨¡å‹çš„è¶…å‚æ•°
        h = model.hyp  # hyperparameters

        # Define criteria
        # å®šä¹‰åˆ†ç±»æŸå¤±å’Œç½®ä¿¡åº¦æŸå¤±
        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))

        # æ ‡ç­¾å¹³æ»‘  eps=0ä»£è¡¨ä¸åšæ ‡ç­¾å¹³æ»‘-> cp=1 cn=0 /  eps!=0ä»£è¡¨åšæ ‡ç­¾å¹³æ»‘ 
        # cpä»£è¡¨æ­£æ ·æœ¬çš„æ ‡ç­¾å€¼ cnä»£è¡¨è´Ÿæ ·æœ¬çš„æ ‡ç­¾å€¼
        # è¯·å‚è€ƒï¼šClass label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

        # Focal loss ä»£æ›¿åŸæœ¬çš„BCEclså’ŒBCEobj
        g = h['fl_gamma']  # focal loss gamma; g=0 ä»£è¡¨ä¸ç”¨focal loss
        if g > 0:
            # å¦‚æœ g>0 å°†åˆ†ç±»æŸå¤±å’Œç½®ä¿¡åº¦æŸå¤±(BCE)éƒ½æ¢æˆ FocalLoss æŸå¤±å‡½æ•°
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)

        # m: è¿”å›çš„æ˜¯æ¨¡å‹çš„3ä¸ªæ£€æµ‹å¤´åˆ†åˆ«å¯¹åº”äº§ç”Ÿçš„3ä¸ªè¾“å‡ºç‰¹å¾å›¾
        m = de_parallel(model).model[-1]  # Detect() module
        """self.balance  ç”¨æ¥å®ç° obj,box,cls loss ä¹‹é—´æƒé‡çš„å¹³è¡¡
        {3: [4.0, 1.0, 0.4]} è¡¨ç¤ºæœ‰ä¸‰ä¸ªlayerçš„è¾“å‡ºï¼Œç¬¬ä¸€ä¸ªlayerçš„weightæ˜¯4.0ï¼Œç¬¬äºŒä¸ª1.0ï¼Œç¬¬ä¸‰ä¸ªä»¥æ­¤ç±»æ¨ã€‚
        å¦‚æœæœ‰5ä¸ªlayerçš„è¾“å‡ºï¼Œé‚£ä¹ˆæƒé‡åˆ†åˆ«æ˜¯[4.0, 1.0, 0.25, 0.06, 0.02]
        """
        self.balance = {3: [4.0, 1.0, 0.4]}.get(m.nl, [4.0, 1.0, 0.25, 0.06, 0.02])  # P3-P7
        # ä¸‰ä¸ªæ£€æµ‹å¤´çš„ä¸‹é‡‡æ ·ç‡ m.stride: [8, 16, 32]  .index(16): æ±‚å‡ºä¸‹é‡‡æ ·ç‡ stride=16 çš„ç´¢å¼•
        # è¿™ä¸ªå‚æ•°ä¼šç”¨æ¥è‡ªåŠ¨è®¡ç®—æ›´æ–° 3 ä¸ª feature map çš„ç½®ä¿¡åº¦æŸå¤±ç³»æ•° self.balance
        self.ssi = list(m.stride).index(16) if autobalance else 0  # stride 16 index
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance
        self.na = m.na  # number of anchors æ¯ä¸ªgrid_cellçš„anchoræ•°é‡ = 3
        self.nc = m.nc  # number of classes æ•°æ®é›†çš„æ€»ç±»åˆ« = 80
        self.nl = m.nl  # number of layers æ£€æµ‹å¤´çš„ä¸ªæ•° = 3
        # anchors: å½¢çŠ¶ [3, 3, 2]  ä»£è¡¨ 3 ä¸ª feature map æ¯ä¸ª feature map ä¸Šæœ‰ 3 ä¸ª anchor(w,h)
        # è¿™é‡Œçš„ anchors å°ºå¯¸æ˜¯ç›¸å¯¹ feature map çš„
        self.anchors = m.anchors
        self.device = device

    def __call__(self, p, targets):  # predictions, targets
        lcls = torch.zeros(1, device=self.device)  # class loss
        lbox = torch.zeros(1, device=self.device)  # box loss
        lobj = torch.zeros(1, device=self.device)  # object loss
        tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets

        # Losses
        for i, pi in enumerate(p):  # layer index, layer predictions
            b, a, gj, gi = indices[i]  # image, anchor, gridy, gridx
            tobj = torch.zeros(pi.shape[:4], dtype=pi.dtype, device=self.device)  # target obj

            n = b.shape[0]  # number of targets
            if n:
                # pxy, pwh, _, pcls = pi[b, a, gj, gi].tensor_split((2, 4, 5), dim=1)  # faster, requires torch 1.8.0
                pxy, pwh, _, pcls = pi[b, a, gj, gi].split((2, 2, 1, self.nc), 1)  # target-subset of predictions

                # Regression
                pxy = pxy.sigmoid() * 2 - 0.5
                pwh = (pwh.sigmoid() * 2) ** 2 * anchors[i]
                pbox = torch.cat((pxy, pwh), 1)  # predicted box
                iou = bbox_iou(pbox, tbox[i], CIoU=True).squeeze()  # iou(prediction, target)
                lbox += (1.0 - iou).mean()  # iou loss

                # Objectness
                iou = iou.detach().clamp(0).type(tobj.dtype)
                if self.sort_obj_iou:
                    j = iou.argsort()
                    b, a, gj, gi, iou = b[j], a[j], gj[j], gi[j], iou[j]
                if self.gr < 1:
                    iou = (1.0 - self.gr) + self.gr * iou
                tobj[b, a, gj, gi] = iou  # iou ratio

                # Classification
                if self.nc > 1:  # cls loss (only if multiple classes)
                    t = torch.full_like(pcls, self.cn, device=self.device)  # targets
                    t[range(n), tcls[i]] = self.cp
                    lcls += self.BCEcls(pcls, t)  # BCE

                # Append targets to text file
                # with open('targets.txt', 'a') as file:
                #     [file.write('%11.5g ' * 4 % tuple(x) + '\n') for x in torch.cat((txy[i], twh[i]), 1)]

            obji = self.BCEobj(pi[..., 4], tobj)
            lobj += obji * self.balance[i]  # obj loss
            if self.autobalance:
                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()

        if self.autobalance:
            self.balance = [x / self.balance[self.ssi] for x in self.balance]
        lbox *= self.hyp['box']
        lobj *= self.hyp['obj']
        lcls *= self.hyp['cls']
        bs = tobj.shape[0]  # batch size

        return (lbox + lobj + lcls) * bs, torch.cat((lbox, lobj, lcls)).detach()

    # build_targets å‡½æ•°ç”¨äºè·å¾—åœ¨è®­ç»ƒæ—¶è®¡ç®— loss æ‰€éœ€è¦çš„ç›®æ ‡æ¡†ï¼Œä¹Ÿå³æ­£æ ·æœ¬ã€‚ä¸yolov3/v4çš„ä¸åŒï¼Œyolov5æ”¯æŒè·¨ç½‘æ ¼é¢„æµ‹ã€‚
    # å¯¹äºä»»ä½•ä¸€ä¸ª GT bboxï¼Œä¸‰ä¸ªé¢„æµ‹ç‰¹å¾å±‚ä¸Šéƒ½å¯èƒ½æœ‰å…ˆéªŒæ¡†åŒ¹é…ï¼Œæ‰€ä»¥è¯¥å‡½æ•°è¾“å‡ºçš„æ­£æ ·æœ¬æ¡†æ¯”ä¼ å…¥çš„ targets ï¼ˆGTæ¡†ï¼‰æ•°ç›®å¤š
    # å…·ä½“å¤„ç†è¿‡ç¨‹:
    # (1)é¦–å…ˆé€šè¿‡ bbox ä¸å½“å‰å±‚ anchor åšä¸€éè¿‡æ»¤ã€‚å¯¹äºä»»ä½•ä¸€å±‚è®¡ç®—å½“å‰ bbox ä¸å½“å‰å±‚ anchor çš„åŒ¹é…ç¨‹åº¦ï¼Œä¸é‡‡ç”¨IoUï¼Œè€Œé‡‡ç”¨shapeæ¯”ä¾‹ã€‚å¦‚æœanchorä¸bboxçš„å®½é«˜æ¯”å·®è·å¤§äº4ï¼Œåˆ™è®¤ä¸ºä¸åŒ¹é…ï¼Œæ­¤æ—¶å¿½ç•¥ç›¸åº”çš„bboxï¼Œå³å½“åšèƒŒæ™¯;
    # (2)æ ¹æ®ç•™ä¸‹çš„bboxï¼Œåœ¨ä¸Šä¸‹å·¦å³å››ä¸ªç½‘æ ¼å››ä¸ªæ–¹å‘æ‰©å¢é‡‡æ ·ï¼ˆå³å¯¹ bbox è®¡ç®—è½åœ¨çš„ç½‘æ ¼æ‰€æœ‰ anchors éƒ½è®¡ç®— loss(å¹¶ä¸æ˜¯ç›´æ¥å’Œ GT æ¡†æ¯”è¾ƒè®¡ç®— loss) )
    # æ³¨æ„æ­¤æ—¶è½åœ¨ç½‘æ ¼ä¸å†æ˜¯ä¸€ä¸ªï¼Œè€Œæ˜¯é™„è¿‘çš„å¤šä¸ªï¼Œè¿™æ ·å°±å¢åŠ äº†æ­£æ ·æœ¬æ•°ã€‚
    # yolov5 æ²¡æœ‰ conf åˆ†æ”¯å¿½ç•¥é˜ˆå€¼(ignore_thresh)çš„æ“ä½œï¼Œè€Œyoloy3/v4æœ‰ã€‚
    def build_targets(self, p, targets):
        # Build targets for compute_loss(), input targets(image,class,x,y,w,h)
        """æ‰€æœ‰GTç­›é€‰ç›¸åº”çš„anchoræ­£æ ·æœ¬
        è¿™é‡Œé€šè¿‡
        p       : list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85])
        targets : targets.shape[314, 6] 

        Args:
            p (_type_): p[i]çš„ä½œç”¨åªæ˜¯å¾—åˆ°æ¯ä¸ª feature map çš„shape
                        é¢„æµ‹æ¡† ç”±æ¨¡å‹æ„å»ºä¸­çš„ä¸‰ä¸ªæ£€æµ‹å¤´ Detector è¿”å›çš„ä¸‰ä¸ª yolo å±‚çš„è¾“å‡º
                        tensoræ ¼å¼ liståˆ—è¡¨ å­˜æ”¾ä¸‰ä¸ªtensor å¯¹åº”çš„æ˜¯ä¸‰ä¸ªyoloå±‚çš„è¾“å‡º
                        å¦‚: list([16, 3, 80, 80, 85], [16, 3, 40, 40, 85],[16, 3, 20, 20, 85])
                        [bs, anchor_num, grid_h, grid_w, xywh+class+classes]
                        å¯ä»¥çœ‹å‡ºæ¥è¿™é‡Œçš„é¢„æµ‹å€¼pæ˜¯ä¸‰ä¸ªyoloå±‚æ¯ä¸ªgrid_cell(æ¯ä¸ªgrid_cellæœ‰ä¸‰ä¸ªé¢„æµ‹å€¼)çš„é¢„æµ‹å€¼,åé¢è‚¯å®šè¦è¿›è¡Œæ­£æ ·æœ¬ç­›é€‰
            targets (_type_): æ•°æ®å¢å¼ºåçš„çœŸå®æ¡† [63, 6] [num_target,  image_index+class+xywh] xywhä¸ºå½’ä¸€åŒ–åçš„æ¡†

        Returns:
            tcls: è¡¨ç¤ºè¿™ä¸ªtargetæ‰€å±çš„class index
            tbox: xywh å…¶ä¸­xyä¸ºè¿™ä¸ªtargetå¯¹å½“å‰grid_cellå·¦ä¸Šè§’çš„åç§»é‡
            indices: b: è¡¨ç¤ºè¿™ä¸ªtargetå±äºçš„image index
                     a: è¡¨ç¤ºè¿™ä¸ªtargetä½¿ç”¨çš„anchor index
                    gj: ç»è¿‡ç­›é€‰åç¡®å®šæŸä¸ªtargetåœ¨æŸä¸ªç½‘æ ¼ä¸­è¿›è¡Œé¢„æµ‹(è®¡ç®—æŸå¤±)  gjè¡¨ç¤ºè¿™ä¸ªç½‘æ ¼çš„å·¦ä¸Šè§’yåæ ‡
                    gi: è¡¨ç¤ºè¿™ä¸ªç½‘æ ¼çš„å·¦ä¸Šè§’xåæ ‡
            anch: è¡¨ç¤ºè¿™ä¸ªtargetæ‰€ä½¿ç”¨anchorçš„å°ºåº¦ï¼ˆç›¸å¯¹äºè¿™ä¸ªfeature mapï¼‰  æ³¨æ„å¯èƒ½ä¸€ä¸ªtargetä¼šä½¿ç”¨å¤§å°ä¸åŒanchorè¿›è¡Œè®¡ç®—
        """
        # na = 3 ; nt = 314
        na, nt = self.na, targets.shape[0]  # number of anchors, targets
        tcls, tbox, indices, anch = [], [], [], []
        # gain.shape=[7]
        gain = torch.ones(7, device=self.device)  # normalized to gridspace gain
        # ai.shape = (na,nt) ç”Ÿæˆanchorç´¢å¼•
        # anchorç´¢å¼•ï¼Œåé¢æœ‰ç”¨ï¼Œç”¨äºè¡¨ç¤ºå½“å‰bboxå’Œå½“å‰å±‚çš„å“ªä¸ªanchoråŒ¹é…
        # éœ€è¦åœ¨3ä¸ªanchorä¸Šéƒ½è¿›è¡Œè®­ç»ƒ æ‰€ä»¥å°†æ ‡ç­¾èµ‹å€¼na=3ä¸ª 
        #  aiä»£è¡¨3ä¸ªanchorä¸Šåœ¨æ‰€æœ‰çš„targetå¯¹åº”çš„anchorç´¢å¼• å°±æ˜¯ç”¨æ¥æ ‡è®°ä¸‹å½“å‰è¿™ä¸ªtargetå±äºå“ªä¸ªanchor
        # [1, 3] -> [3, 1] -> [3, 314]=[na, nt]   ä¸‰è¡Œ  ç¬¬ä¸€è¡Œ63ä¸ª0  ç¬¬äºŒè¡Œ63ä¸ª1  ç¬¬ä¸‰è¡Œ63ä¸ª2
        # ai.shape  =[3, 314]
        ai = torch.arange(na, device=self.device).float().view(na, 1).repeat(1, nt)  # same as .repeat_interleave(nt)
        # [314, 6] [3, 314] -> [3, 314, 6] [3, 314, 1] -> [3, 314, 7]  7: [image_index+class+xywh+anchor_index]
        # å¯¹æ¯ä¸€ä¸ªfeature map: è¿™ä¸€æ­¥æ˜¯å°†targetå¤åˆ¶ä¸‰ä»½ å¯¹åº”ä¸€ä¸ªfeature mapçš„ä¸‰ä¸ªanchor
        # å…ˆå‡è®¾æ‰€æœ‰çš„targetéƒ½ç”±è¿™å±‚çš„ä¸‰ä¸ªanchorè¿›è¡Œæ£€æµ‹(å¤åˆ¶ä¸‰ä»½)  å†è¿›è¡Œç­›é€‰  å¹¶å°†aiåŠ è¿›å»æ ‡è®°å½“å‰æ˜¯å“ªä¸ªanchorçš„target
        # targets.shape = [3, 314, 7]
        targets = torch.cat((targets.repeat(na, 1, 1), ai[..., None]), 2)  # append anchor indices
        # è¿™ä¸¤ä¸ªå˜é‡æ˜¯ç”¨æ¥æ‰©å±•æ­£æ ·æœ¬çš„ å› ä¸ºé¢„æµ‹æ¡†é¢„æµ‹åˆ°targetæœ‰å¯èƒ½ä¸æ­¢å½“å‰çš„æ ¼å­é¢„æµ‹åˆ°äº†
        # å¯èƒ½å‘¨å›´çš„æ ¼å­ä¹Ÿé¢„æµ‹åˆ°äº†é«˜è´¨é‡çš„æ ·æœ¬ æˆ‘ä»¬ä¹Ÿè¦æŠŠè¿™éƒ¨åˆ†çš„é¢„æµ‹ä¿¡æ¯åŠ å…¥æ­£æ ·æœ¬ä¸­
        # è®¾ç½®ç½‘æ ¼ä¸­å¿ƒåç§»é‡
        g = 0.5  # bias
        # é™„è¿‘çš„4ä¸ªæ¡†
        # ä»¥è‡ªèº« + å‘¨å›´å·¦ä¸Šå³ä¸‹4ä¸ªç½‘æ ¼ = 5ä¸ªç½‘æ ¼  ç”¨æ¥è®¡ç®—offsets
        off = torch.tensor(
            [
                [0, 0],
                [1, 0],
                [0, 1],
                [-1, 0],
                [0, -1],  # j,k,l,m
                # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm
            ],
            device=self.device).float() * g  # offsets
        # å¯¹æ¯ä¸ªæ£€æµ‹å±‚è¿›è¡Œå¤„ç† 
        # éå†ä¸‰ä¸ªfeature ç­›é€‰gtçš„anchoræ­£æ ·æœ¬
        for i in range(self.nl): #  self.nl: number of detection layers   Detectçš„ä¸ªæ•° = 3
            # anchors: å½“å‰feature mapå¯¹åº”çš„ä¸‰ä¸ªanchorå°ºå¯¸(ç›¸å¯¹feature map)  [3, 2]
            anchors, shape = self.anchors[i], p[i].shape
            # gain: ä¿å­˜æ¯ä¸ªè¾“å‡ºfeature mapçš„å®½é«˜ -> gain[2:6] = torch.tensor(shape)[[3, 2, 3, 2]] 
            # [1, 1, 1, 1, 1, 1, 1] -> [1, 1, 112, 112, 112,112, 1]=image_index+class+xywh+anchor_index
            gain[2:6] = torch.tensor(shape)[[3, 2, 3, 2]]  # xyxy gain

            # Match targets to anchors
            # t.shape = [3, 314, 7]  å°†targetä¸­çš„xywhçš„å½’ä¸€åŒ–å°ºåº¦æ”¾ç¼©åˆ°ç›¸å¯¹å½“å‰feature mapçš„åæ ‡å°ºåº¦
            #    [3, 314, image_index+class+xywh+anchor_index]
            t = targets * gain  # shape(3,n,7)
            if nt: # å¦‚æœæœ‰ç›®æ ‡å°±å¼€å§‹åŒ¹é…
                # Matches
                # æ‰€æœ‰çš„gtä¸å½“å‰å±‚çš„ä¸‰ä¸ªanchorçš„å®½é«˜æ¯”(w/w  h/h)
                # r.shape = [3, 314, 2]
                r = t[..., 4:6] / anchors[:, None]  # wh ratio
                # ç­›é€‰æ¡ä»¶  GTä¸anchorçš„å®½æ¯”æˆ–é«˜æ¯”è¶…è¿‡ä¸€å®šçš„é˜ˆå€¼ å°±å½“ä½œè´Ÿæ ·æœ¬
                # torch.max(r, 1. / r)=[3, 314, 2] ç­›é€‰å‡ºå®½æ¯”w1/w2 w2/w1 é«˜æ¯”h1/h2 h2/h1ä¸­æœ€å¤§çš„é‚£ä¸ª
                # .max(2)è¿”å›å®½æ¯” é«˜æ¯”ä¸¤è€…ä¸­è¾ƒå¤§çš„ä¸€ä¸ªå€¼å’Œå®ƒçš„ç´¢å¼•  [0]è¿”å›è¾ƒå¤§çš„ä¸€ä¸ªå€¼
                # j.shape = [3, 314]  False: å½“å‰anchoræ˜¯å½“å‰gtçš„è´Ÿæ ·æœ¬  True: å½“å‰anchoræ˜¯å½“å‰gtçš„æ­£æ ·æœ¬
                j = torch.max(r, 1 / r).max(2)[0] < self.hyp['anchor_t']  # compare
                # yolov3 v4çš„ç­›é€‰æ–¹æ³•: wh_iou  GTä¸anchorçš„wh_iouè¶…è¿‡ä¸€å®šçš„é˜ˆå€¼å°±æ˜¯æ­£æ ·æœ¬
                # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))

                # æ ¹æ®ç­›é€‰æ¡ä»¶j, è¿‡æ»¤è´Ÿæ ·æœ¬, å¾—åˆ°æ‰€æœ‰gtçš„anchoræ­£æ ·æœ¬(batch_sizeå¼ å›¾ç‰‡)
                # çŸ¥é“å½“å‰gtçš„åæ ‡ å±äºå“ªå¼ å›¾ç‰‡ æ­£æ ·æœ¬å¯¹åº”çš„idx ä¹Ÿå°±å¾—åˆ°äº†å½“å‰gtçš„æ­£æ ·æœ¬anchor
                # t: [3, 314, 7] -> [555, 7]  [num_Positive_sample, image_index+class+xywh+anchor_index]
                t = t[j]  # filter

                # Offsets ç­›é€‰å½“å‰æ ¼å­å‘¨å›´æ ¼å­ æ‰¾åˆ° 2 ä¸ªç¦»targetä¸­å¿ƒæœ€è¿‘çš„ä¸¤ä¸ªæ ¼å­  
                # å¯èƒ½å‘¨å›´çš„æ ¼å­ä¹Ÿé¢„æµ‹åˆ°äº†é«˜è´¨é‡çš„æ ·æœ¬ æˆ‘ä»¬ä¹Ÿè¦æŠŠè¿™éƒ¨åˆ†çš„é¢„æµ‹ä¿¡æ¯åŠ å…¥æ­£æ ·æœ¬ä¸­
                # é™¤äº†targetæ‰€åœ¨çš„å½“å‰æ ¼å­å¤–, è¿˜æœ‰2ä¸ªæ ¼å­å¯¹ç›®æ ‡è¿›è¡Œæ£€æµ‹(è®¡ç®—æŸå¤±) 
                # ä¹Ÿå°±æ˜¯è¯´ä¸€ä¸ªç›®æ ‡éœ€è¦3ä¸ªæ ¼å­å»é¢„æµ‹(è®¡ç®—æŸå¤±)
                # é¦–å…ˆå½“å‰æ ¼å­æ˜¯å…¶ä¸­1ä¸ª å†ä»å½“å‰æ ¼å­çš„ä¸Šä¸‹å·¦å³å››ä¸ªæ ¼å­ä¸­é€‰æ‹©2ä¸ª
                # ç”¨è¿™ä¸‰ä¸ªæ ¼å­å»é¢„æµ‹è¿™ä¸ªç›®æ ‡(è®¡ç®—æŸå¤±)
                # feature mapä¸Šçš„åŸç‚¹åœ¨å·¦ä¸Šè§’ å‘å³ä¸ºxè½´æ­£åæ ‡ å‘ä¸‹ä¸ºyè½´æ­£åæ ‡
                # grid xy å–targetä¸­å¿ƒçš„åæ ‡xy(ç›¸å¯¹feature mapå·¦ä¸Šè§’çš„åæ ‡)
                # gxy.shape = [555, 2]
                gxy = t[:, 2:4]  # grid xy
                # inverse  å¾—åˆ°targetä¸­å¿ƒç‚¹ç›¸å¯¹äºå³ä¸‹è§’çš„åæ ‡  gain[[2, 3]]ä¸ºå½“å‰feature mapçš„wh
                # gxi.shape = [555, 2]
                gxi = gain[[2, 3]] - gxy  # inverse
                # ç­›é€‰ä¸­å¿ƒåæ ‡è·ç¦»å½“å‰grid_cellçš„å·¦ã€ä¸Šæ–¹åç§»å°äºg=0.5 
                # ä¸” ä¸­å¿ƒåæ ‡å¿…é¡»å¤§äº1(åæ ‡ä¸èƒ½åœ¨è¾¹ä¸Š æ­¤æ—¶å°±æ²¡æœ‰4ä¸ªæ ¼å­äº†)
                # j: [555] bool å¦‚æœæ˜¯Trueè¡¨ç¤ºå½“å‰targetä¸­å¿ƒç‚¹æ‰€åœ¨çš„æ ¼å­çš„å·¦è¾¹æ ¼å­ä¹Ÿå¯¹è¯¥targetè¿›è¡Œå›å½’(åç»­è¿›è¡Œè®¡ç®—æŸå¤±)
                # k: [555] bool å¦‚æœæ˜¯Trueè¡¨ç¤ºå½“å‰targetä¸­å¿ƒç‚¹æ‰€åœ¨çš„æ ¼å­çš„ä¸Šè¾¹æ ¼å­ä¹Ÿå¯¹è¯¥targetè¿›è¡Œå›å½’(åç»­è¿›è¡Œè®¡ç®—æŸå¤±)
                j, k = ((gxy % 1 < g) & (gxy > 1)).T
                # ç­›é€‰ä¸­å¿ƒåæ ‡è·ç¦»å½“å‰grid_cellçš„å³ã€ä¸‹æ–¹åç§»å°äºg=0.5 ä¸” ä¸­å¿ƒåæ ‡å¿…é¡»å¤§äº1(åæ ‡ä¸èƒ½åœ¨è¾¹ä¸Š æ­¤æ—¶å°±æ²¡æœ‰4ä¸ªæ ¼å­äº†)
                # l: [555] bool å¦‚æœæ˜¯Trueè¡¨ç¤ºå½“å‰targetä¸­å¿ƒç‚¹æ‰€åœ¨çš„æ ¼å­çš„å³è¾¹æ ¼å­ä¹Ÿå¯¹è¯¥targetè¿›è¡Œå›å½’(åç»­è¿›è¡Œè®¡ç®—æŸå¤±)
                # m: [555] bool å¦‚æœæ˜¯Trueè¡¨ç¤ºå½“å‰targetä¸­å¿ƒç‚¹æ‰€åœ¨çš„æ ¼å­çš„ä¸‹è¾¹æ ¼å­ä¹Ÿå¯¹è¯¥targetè¿›è¡Œå›å½’(åç»­è¿›è¡Œè®¡ç®—æŸå¤±)
                l, m = ((gxi % 1 < g) & (gxi > 1)).T
                # j.shape=[5, 555]
                j = torch.stack((torch.ones_like(j), j, k, l, m))
                # å¾—åˆ°ç­›é€‰åæ‰€æœ‰æ ¼å­çš„æ­£æ ·æœ¬ æ ¼å­æ•°<=3*555 éƒ½ä¸åœ¨è¾¹ä¸Šç­‰å·æˆç«‹
                # t: [555, 7] -> å¤åˆ¶ 5 ä»½target[5, 555, 7]  åˆ†åˆ«å¯¹åº”å½“å‰æ ¼å­å’Œå·¦ä¸Šå³ä¸‹æ ¼å­5ä¸ªæ ¼å­
                # ä½¿ç”¨ j ç­›é€‰å t çš„å½¢çŠ¶: [1659, 7] 
                t = t.repeat((5, 1, 1))[j]
                # flow.zeros_like(gxy)[None]: [1, 555, 2]   off[:, None]: [5, 1, 2]  => [5, 555, 2]
                # å¾—åˆ°æ‰€æœ‰ç­›é€‰åçš„ç½‘æ ¼çš„ä¸­å¿ƒç›¸å¯¹äºè¿™ä¸ªè¦é¢„æµ‹çš„çœŸå®æ¡†æ‰€åœ¨ç½‘æ ¼è¾¹ç•Œ
                # ï¼ˆå·¦å³ä¸Šä¸‹è¾¹æ¡†ï¼‰çš„åç§»é‡ï¼Œç„¶åé€šè¿‡ j ç­›é€‰æœ€ç»ˆ offsets çš„å½¢çŠ¶æ˜¯ [1659, 2]
                offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]
            else:
                t = targets[0]
                offsets = 0

            # Define
            # bc.shape = [1659, 2]
            # gxy.shape = [1659, 2]
            # gwh.shape  = [1659, 2]
            # a.shape = [1659, 1]
            bc, gxy, gwh, a = t.chunk(4, 1)  # (image, class), grid xy, grid wh, anchors
            # a, (b, c) = a.long().view(-1), bc.long().T  # anchors, image, class
            # a.shape = [1659]
            # (b, c).shape = [1659, 2]
            a, (b, c) = a.long().view(-1), bc.long().T  # anchors, image, class
            gij = (gxy - offsets).long()
            # é¢„æµ‹çœŸå®æ¡†çš„ç½‘æ ¼æ‰€åœ¨çš„å·¦ä¸Šè§’åæ ‡(æœ‰å·¦ä¸Šå³ä¸‹çš„ç½‘æ ¼)  
            # gij.shape = [1659, 2]
            
            # è¿™é‡Œçš„æ‹†åˆ†æˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„ç¤ºä¾‹ä»£ç æ¥è¿›è¡Œè§£é‡Šï¼š

            # x = torch.randn(3, 2)
            # y, z = x.T
            # print(y.shape)
            # print(z.shape)

            # => torch.Size([3])
            # => torch.Size([3])

            # å› æ­¤ï¼š
            # gi.shape = [1659]
            # gj.shape = [1659]
            gi, gj = gij.T  # grid indices

            # Append

            # gi.shape = [1659]
            # gj.shape = [1659]
            # gi = gi.clamp(0, shape[3] - 1)
            # gj = gj.clamp(0, shape[2] - 1)
            # b: image index  a: anchor index  gj: ç½‘æ ¼çš„å·¦ä¸Šè§’yåæ ‡  gi: ç½‘æ ¼çš„å·¦ä¸Šè§’xåæ ‡
            indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1)))  # image, anchor, grid
            # tbox: xywh å…¶ä¸­xyä¸ºè¿™ä¸ªtargetå¯¹å½“å‰grid_cellå·¦ä¸Šè§’çš„åç§»é‡
            tbox.append(torch.cat((gxy - gij, gwh), 1))  # box
            anch.append(anchors[a])  # anchors å¯¹åº”çš„æ‰€æœ‰anchors
            tcls.append(c)  # class

        return tcls, tbox, indices, anch
    
# å‚è€ƒï¼šhttps://zhuanlan.zhihu.com/p/591833099
